{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import audio\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0 BlackHole 16ch, Core Audio (16 in, 16 out)\n",
      "< 1 Externe KopfhÃ¶rer, Core Audio (0 in, 2 out)\n",
      "> 2 MacBook Pro-Mikrofon, Core Audio (1 in, 0 out)\n",
      "  3 MacBook Pro-Lautsprecher, Core Audio (0 in, 2 out)\n",
      "  4 Microsoft Teams Audio, Core Audio (2 in, 2 out)\n",
      "  5 ZoomAudioDevice, Core Audio (2 in, 2 out)\n",
      "  6 BH-1-2, Core Audio (16 in, 16 out)\n",
      "  7 BH-3-4, Core Audio (16 in, 16 out)\n",
      "  8 Multi-Output Device, Core Audio (0 in, 2 out)\n"
     ]
    }
   ],
   "source": [
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioClassifier = mp.tasks.audio.AudioClassifier\n",
    "AudioClassifierOptions = mp.tasks.audio.AudioClassifierOptions\n",
    "AudioClassifierResult = mp.tasks.audio.AudioClassifierResult\n",
    "AudioRunningMode = mp.tasks.audio.RunningMode\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "\n",
    "def print_result(result: AudioClassifierResult, timestamp_ms: int):\n",
    "    print('AudioClassifierResult result: {}'.format(result))\n",
    "\n",
    "options = AudioClassifierOptions(\n",
    "    base_options=BaseOptions(model_asset_path='yamnet-classification.tflite'),\n",
    "    running_mode=AudioRunningMode.AUDIO_STREAM,\n",
    "    max_results=5,\n",
    "    result_callback=print_result)\n",
    "\n",
    "# with AudioClassifier.create_from_options(options) as classifier:\n",
    "#   # The classifier is initialized. Use it here.\n",
    "#   # ...\n",
    "#   print('something')\n",
    "\n",
    "\n",
    "# Send live audio data to perform audio classification.\n",
    "# Results are sent to the `result_callback` provided in the `AudioClassifierOptions`\n",
    "# classifier.classify_async(audio_data, timestamp_ms)\n",
    "# Create the audio classifier\n",
    "classifier = AudioClassifier.create_from_options(options)\n",
    "  \n",
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "AudioData = mp.tasks.components.containers.AudioData\n",
    "\n",
    "\n",
    "# Parameters\n",
    "fs = 44100.0  # Sample rate\n",
    "sample_rate = 16000\n",
    "channels = 1  # Mono audio\n",
    "block_size = 256  # Number of samples per callback\n",
    "device_index = 2  # Replace with your desired input device index\n",
    "\n",
    "# Read microphone data as np arrays, then call\n",
    "\n",
    "# Callback function to process audio in real-time\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(status, flush=True)  # Handle errors\n",
    "    print(\"Received block with shape:\", indata.shape)  # Process audio here\n",
    "    # Flatten the input data and convert to a list\n",
    "    # audio_data = np.reshape(indata, -1).tolist()\n",
    "    # Get the current timestamp in milliseconds\n",
    "    timestamp_ms = int(time.inputBufferAdcTime * 1000)\n",
    "    # Create an AudioData object\n",
    "    # mp_audio_data = AudioData(\n",
    "    #   buffer=audio_data,\n",
    "    #   sample_rate=sample_rate  # Adjust based on your model requirements\n",
    "    # )\n",
    "    # mp_audio_data = AudioData(\n",
    "    #     buffer=audio_data,\n",
    "    #     sample_rate=sample_rate\n",
    "    # )\n",
    "    # Send the audio data to the classifier\n",
    "    # classifier.classify_async(mp_audio_data, timestamp_ms)\n",
    "    # audio_data = AudioData.create_from_array(indata.astype(float) / np.iinfo(np.int16).max, fs)\n",
    "    # Get the current timestamp in milliseconds\n",
    "    # timestamp_ms = int(time.inputBufferAdcTime * 1000)\n",
    "    # classifier.classify_async(audio_data, timestamp_ms)\n",
    "    # time.sleep(0.9)\n",
    "    # Convert NumPy array to a raw byte buffer\n",
    "    # audio_data_bytes = np.array(indata, dtype=np.float32).tobytes()\n",
    "\n",
    "    # # Create AudioData instance\n",
    "    # mp_audio_data = AudioData.create_from_array(audio_data_bytes, sample_rate=sample_rate)\n",
    "    # Ensure audio data is in float32 format (required by MediaPipe)\n",
    "    audio_data_np = np.array(indata, dtype=np.float32)\n",
    "\n",
    "    # Create AudioData instance correctly\n",
    "    mp_audio_data = AudioData.create_from_array(audio_data_np, sample_rate=sample_rate)\n",
    "    classifier.classify_async(mp_audio_data, timestamp_ms)\n",
    "\n",
    "# Open a stream with the selected device\n",
    "with sd.InputStream(samplerate=sample_rate, channels=channels, callback=audio_callback,blocksize=block_size, device=6):\n",
    "    print(\"Streaming from device:\", device_index)\n",
    "    print(\"Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "      while True:\n",
    "        time.sleep(0.9)\n",
    "        pass  # Keep the stream open\n",
    "    except KeyboardInterrupt:\n",
    "      print('stpped!')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
